{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/03_Aprendizaje-Por-Refuerzo.ipynb) üëàüèª‚Äã **Pulsar para abrir en Colab‚Äã**\n",
    "\n",
    "# ¬øC√≥mo usar estos notebooks?\n",
    "\n",
    "Si este es el primer notebook que abres en este repositorio, te recomiendo que antes leas el [Manual de uso de estos notebooks](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/docs/manual-notebooks.md) que he creado para que te familiarices con el proyecto y las distintas rutas que puedes seguir, luego puedes volver aqu√≠ y continuar.\n",
    "\n",
    "En este notebook, vamos a profundizar en el aprendizaje por refuerzo.\n",
    "\n",
    "Por otra parte, si a√∫n no has revisado el notebook \"[00_Empieza-aqu√≠.ipynb](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/00_Empieza-aqu√≠.ipynb)\", te sugiero que le eches un vistazo primero para conocer los conceptos b√°sicos. Pero si ya tienes una idea clara de qu√© es el aprendizaje no supervisado y quieres verlo en acci√≥n, ¬°est√°s en el lugar correcto!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Aprendizaje por Refuerzo\n",
    "\n",
    "El Aprendizaje por Refuerzo (Reinforcement Learning, RL) es un tipo de Machine Learning donde el modelo (llamado **agente**) aprende a trav√©s de la experiencia en un entorno, intentando maximizar una recompensa acumulada a lo largo del tiempo.\n",
    "\n",
    "## ¬øPor qu√© es importante?\n",
    "\n",
    "El RL es fundamental en la inteligencia artificial moderna porque nos permite resolver problemas en los que las decisiones se deben tomar secuencialmente y las consecuencias de una acci√≥n afectan el futuro. Algunos de los avances m√°s emocionantes en IA han sido gracias al aprendizaje por refuerzo:\n",
    "\n",
    "- **Inteligencias artificiales campeonas en juegos:** Desde el m√≠tico [AlphaGo](https://en.wikipedia.org/wiki/AlphaGo) que venci√≥ a los mejores jugadores de Go, hasta bots que dominan videojuegos como [Dota 2](https://arxiv.org/abs/1912.06680) o [StarCraft](https://deepmind.google/discover/blog/alphastar-grandmaster-level-in-starcraft-ii-using-multi-agent-reinforcement-learning/).\n",
    "- **Rob√≥tica avanzada:** Robots que aprenden a caminar, volar o ensamblar piezas en f√°bricas sin un manual de instrucciones.\n",
    "- **Toma de decisiones aut√≥noma:** Algoritmos que optimizan inversiones, rutas de transporte o sistemas energ√©ticos en tiempo real.\n",
    "- **Ciencia y descubrimiento:** Sistemas que dise√±an medicamentos, exploran galaxias o incluso controlan experimentos cient√≠ficos.\n",
    "\n",
    "En esencia, el RL se utiliza cuando necesitamos que una m√°quina aprende a actuar en un entorno complejo y din√°mico, en el que no hay una soluci√≥n clara de antemano.\n",
    "\n",
    "## ¬øQu√© vamos a ver?\n",
    "\n",
    "En este notebook, vamos a explorar el aprendizaje por refuerzo desde sus fundamentos hasta su implementaci√≥n pr√°ctica. El objetivo es que puedas comprender no solo c√≥mo funciona, sino tambi√©n por qu√© es tan poderoso.\n",
    "\n",
    "Al final de este notebook, entender√°s:\n",
    "\n",
    "- **Los fundamentos del RL**, incluyendo conceptos clave como agente, entorno, recompensa y pol√≠tica.\n",
    "- **C√≥mo funciona un agente RL**, su interacci√≥n con el entorno y c√≥mo aprende para maximizar una recompensa acumulada.\n",
    "- **C√≥mo implementar un modelo RL desde cero**, aplic√°ndolo al cl√°sico problema de [CartPole](https://www.gymlibrary.dev/environments/classic_control/cart_pole/).\n",
    "- **C√≥mo aplicar RL a diferentes disciplinas**, como negocios, videojuegos, rob√≥tica y m√°s.\n",
    "\n",
    "**¬øListo para empezar a explorar el fascinante mundo del aprendizaje por refuerzo?**\n",
    "\n",
    "**¬°Empecemos!üöÄ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# √çndice de Contenidos\n",
    "\n",
    "```\n",
    "1. Fundamentos del Aprendizaje por Refuerzo\n",
    "   1.1. Componentes clave del RL  \n",
    "      1.1.1. Agente, entorno y recompensa  \n",
    "      1.1.2. Pol√≠tica, funci√≥n de valor y funci√≥n Q  \n",
    "   1.2. Exploraci√≥n vs. explotaci√≥n: el equilibrio perfecto  \n",
    "2. Tabular Q-Learning: Un primer paso pr√°ctico\n",
    "   2.1. Descripci√≥n del problema: un agente en una cuadr√≠cula  \n",
    "   2.2. Configuraci√≥n del entorno  \n",
    "   2.3. Implementaci√≥n del algoritmo Tabular Q-Learning  \n",
    "      2.3.1. Inicializaci√≥n de la tabla Q  \n",
    "      2.3.2. Actualizaci√≥n de valores Q   \n",
    "   2.4. Visualizaci√≥n del aprendizaje del agente\n",
    "3. OpenAI Gym y el problema de CartPole\n",
    "   3.1. Introducci√≥n a OpenAI Gym  \n",
    "   3.2. Configuraci√≥n del entorno CartPole  \n",
    "   3.3. Implementaci√≥n de Q-Learning en CartPole  \n",
    "      3.3.1. Entrenamiento del agente  \n",
    "      3.3.2. Visualizaci√≥n del progreso del agente  \n",
    "   3.4. An√°lisis de resultados y reflexiones  \n",
    "4. Conclusi√≥n\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Configuraciones\n",
    "# Detectar si estamos en Colab\n",
    "in_colab = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if in_colab:\n",
    "    # Descargar el archivo visualizations.py desde el repositorio de GitHub\n",
    "    !mkdir -p /content/utils # Creamos una carpeta utils para que coincida con la estructura del repositorio\n",
    "    !wget -O utils/visualizations.py \"https://raw.githubusercontent.com/ManuelEspejo/Machine-Learning-Bases/main/utils/visualizations.py\"\n",
    "    data_dir = '/content/data' # Ruta de los datos\n",
    "else:\n",
    "    # Agregar el directorio ra√≠z al path de Python (Para ejecutar en local)\n",
    "    notebook_dir = os.path.dirname(os.path.abspath('__file__'))\n",
    "    project_dir = os.path.dirname(notebook_dir)\n",
    "    sys.path.append(project_dir)\n",
    "    data_dir = '../data/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaciones\n",
    "\n",
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "from IPython import display # noqa: E402\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.visualizations import *  # noqa: F403"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Componentes clave del RL\n",
    "\n",
    "En este apartado, vamos a desglosar los componentes clave del RL para entender bien c√≥mo podemos aplicarlos a nuestros problemas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.1. Agente, entorno y recompensa\n",
    "\n",
    "En el coraz√≥n del RL, tenemos tres actores principales:\n",
    "\n",
    "#### üßë‚ÄçüöÄ Agente\n",
    "\n",
    "El agente es el protagonista de nuestra historia. Es la entidad que toma decisiones, explora el mundo y aprende de sus errores. En un videojuego, el agente ser√≠a tu personaje controlado. En un robot, el agente ser√≠a el sistema que decide c√≥mo moverse.\n",
    "\n",
    "- **Pregunta clave que se hace el agente**: ¬øQu√© acci√≥n debo tomar ahora?\n",
    "\n",
    "#### üåç Entorno\n",
    "\n",
    "El entorno es el mundo donde el agente vive y act√∫a. Define las reglas del juego y las consecuencias de cada acci√≥n. Es como el tablero de un juego de mesa: puede ser un simple tablero 2D o un mundo complejo como el universo de Minecraft.\n",
    "\n",
    "- **Pregunta clave que se hace el agente**: ¬øC√≥mo responde el mundo a mis acciones?\n",
    "\n",
    "#### üèÜ Recompensa\n",
    "\n",
    "La recompensa es el \"premio\" que el agente obtiene despu√©s de tomar una acci√≥n en el entorno. Es lo que lo motiva a actuar de cierta manera. En un videojuego, la recompensa podr√≠a ser un punto extra por recoger una moneda. En un agente de bolsa,la recompensa podr√≠a ser la ganancia neta despu√©s de una transacci√≥n.\n",
    "\n",
    "- **Pregunta clave que se hace el agente**: ¬øFue buena mi acci√≥n?\n",
    "\n",
    "Las recompensas son lo que determinan c√≥mo el agente ajusta su comportamiento con el tiempo. El agente b√°sicamente vive para maximizar sus recompensas acumuladas, es su prop√≥sito vital. Seg√∫n la situaci√≥n, podemos encontrar los siguientes escenarios de recompensa:\n",
    "\n",
    "- **Recompensa positiva**: La acci√≥n tomada fue buena. El agente recibe un premio.\n",
    "  - *Ejemplo*: Un dron recibe +1 por cada segundo que se mantiene volando hacia el objetivo.\n",
    "\n",
    "- **Recompensa negativa**: La acci√≥n tomada fue mala. El agente recibe una penalizaci√≥n.\n",
    "  - *Ejemplo*: Si el dron choca contra una pared, recibe una penalizaci√≥n de -10.\n",
    "\n",
    "- **Recompensa nula**: La acci√≥n tomada no tiene consecuencias inmediatas. No es ideal, pero tampoco perjudica al agente.\n",
    "  - *Ejemplo*: El dron empieza a volar en c√≠rculos sin progresar hacia el objetivo.\n",
    "\n",
    "#### Escenarios controlados: Evitar la destruccion del mundo\n",
    "\n",
    "Como habr√°s imaginado, no siempre podemos permitir que el agente practique en el mundo real. Imagina un agente aprendiendo a volar un avi√≥n a base de prueba y error. ¬øQu√© podr√≠a salir mal? O que un agente practicando cirug√≠as a coraz√≥n abierto con pacientes reales. No, graciasüôÇ‚Äç‚ÜîÔ∏è‚Äã.\n",
    "\n",
    "Para evitar el caos (y salvar el mundo), utilizamos simuladores de mundos controlados. Estos entornos simulan de manera segura la realidad, permitiendo que el agente practique, falle y aprende sin causar da√±os en el mundo real.\n",
    "\n",
    "¬°Ojo!, esto no s√≥lo aplica a los agentes; los humanos tambi√©n necesitamos simuladores o entornos controlados para practicar, especialmente en actividades complejas como la conducci√≥n o la cirug√≠a. La diferencia es que un agente descontrolado puede tener un potencial de destrucci√≥n mucho mayor (y no se detiene a reflexionar sobre sus errores como nosotros)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2. Pol√≠tica, funci√≥n de valor y funci√≥n Q\n",
    "\n",
    "Ahora que tenemos claro qui√©n es qui√©n, pasemos a los conceptos que gu√≠an el aprendizaje del agente:\n",
    "\n",
    "#### üéØ Pol√≠tica\n",
    "\n",
    "La pol√≠tica es como el \"cerebro\" del agente. Define qu√© acci√≥n tomar en cada situaci√≥n. Puede ser algo tan simple como una tabla de consulta o tan complejo como una red neuronal.\n",
    "\n",
    "- **Ejemplo:** Si el dron est√° cerca de una pared, la pol√≠tica podr√≠a ser: \"Girar a la izquierda para evitarla\".\n",
    "\n",
    "#### üíé Funci√≥n de valor\n",
    "\n",
    "La funci√≥n de valor le dice al agente qu√© tan bueno es estar en un estado espec√≠fico. Es como si el agente tuviera un mapa que indica qu√© lugares son seguros y cu√°les no.\n",
    "\n",
    "- **Ejemplo:** En el caso del dron, un estado cerca de una pared podr√≠a tener un valor bajo (peligroso), mientras que un estado en el centro de la habitaci√≥n tiene un valor alto (seguro).\n",
    "\n",
    "#### üî¢ Funci√≥n Q\n",
    "\n",
    "La funci√≥n Q es un nivel m√°s avanzado: no solo eval√∫a los estados, sino las acciones dentro de esos estados. Es decir, ayuda al agente a decidir cu√°l acci√≥n espec√≠fica maximizar√° la recompensa.\n",
    "\n",
    "- **Ejemplo:** Si el dron est√° en una esquina, la funci√≥n Q le dir√≠a: \"Girando a la derecha tendr√°s una mejor recompensa que avanzando hacia adelante\".\n",
    "\n",
    "\n",
    "#### Analog√≠a: En busca del tesoro\n",
    "\n",
    "Piensa en un explorador en un bosque. La pol√≠tica es su instinto para decidir si gira a la izquierda o a la derecha. La funci√≥n de valor es el mapa que usa para saber qu√© tan lejos est√° del tesoro. La funci√≥n Q combina ambos: \"Si tomo este camino, ¬øqu√© tan r√°pido llegar√© al tesoro?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Exploraci√≥n vs. explotaci√≥n: el equilibrio perfecto\n",
    "\n",
    "En el aprendizaje por refuerzo encontramos un desaf√≠o fundamental: **¬øcu√°ndo explorar y cu√°ndo explotar?**\n",
    "\n",
    "Para que un agente aprenda de manera eficiente, necesita encontrar el equilibrio perfecto entre estas dos estrategias:\n",
    "\n",
    "### Exploraci√≥n\n",
    "\n",
    "La exploraci√≥n consiste en probar nuevas acciones para descubrir m√°s sobre el entorno, incluso si no garantizan una recompensa inmediata. Es como ser un aventurero que se adentra en territorios desconocidos, con la esperanza de encontrar algo valioso.\n",
    "\n",
    "- **Ventaja**: Puede descubrir estrategias o recompensas que no eran evidentes antes.\n",
    "- **Desventaja**: Puede tomar decisiones sub√≥ptimas en el corto plazo, lo que reduce las recompensas inmediatas.\n",
    "- **Ejemplo**: Un robot que explora una nueva habitaci√≥n podr√≠a intentar atravesar una puerta que no hab√≠a detectado antes, descubriendo un camino m√°s corto hacia su objetivo.\n",
    "\n",
    "### Explotaci√≥n\n",
    "\n",
    "La explotaci√≥n significa usar el conocimiento actual para maximizar las recompensas, eligiendo las acciones que ya sabe que funcionan. Es como ir a tu restaurante favorito y pedir ese plato que nunca te falla. ¬øPor qu√© arriesgarse, verdad?\n",
    "\n",
    "- **Ventaja**: Asegura recompensas constantes y predecibles.\n",
    "- **Desventaja**: Limita el descubrimiento de estrategias potencialmente mejores.\n",
    "- **Ejemplo**: El robot, en lugar de explorar nuevas puertas, siempre usa un camino conocido para llegar a su destino, aunque podr√≠a no ser el m√°s eficiente.\n",
    "\n",
    "### ¬øC√≥mo encontrar el equilibrio?\n",
    "\n",
    "La clave est√° en balancear ambas estrategias. Un agente que solo explora nunca aprovecha lo que ha aprendido, mientras que uno que solo explota se queda atascado en soluciones sub√≥ptimas. Encontrar este equilibrio es esencial para que el agente no solo aprenda, sino que tambi√©n logre maximizar su rendimiento.\n",
    "\n",
    "Esto no es solo un dilema de los agentes; ¬°nos pasa a los humanos todo el tiempo! ¬øDeber√≠as pedir ese plato que sabes que te encanta o arriesgarte a probar algo nuevo? ¬øIr de vacaciones al mismo lugar de siempre o aventurarte a descubrir un destino desconocido? Tanto para los agentes como para nosotros, el truco est√° en ser curiosos sin dejar de aprovechar lo que ya sabemos que funciona.\n",
    "\n",
    "Y t√∫, ¬øeres m√°s explorador o explotador?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Tabular Q-Learning: Un primer paso pr√°ctico\n",
    "\n",
    "El **Q-Learning** es uno de los algoritmos m√°s b√°sicos y poderosos en el aprendizaje por refuerzo. Es un m√©todo basado en tablas que permite a un agente aprender la mejor acci√≥n para tomar en cada estado de un entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Descripci√≥n del problema: un agente en una cuadr√≠cula\n",
    "\n",
    "Para este ejemplo, imaginemos que nuestro agente es un explorador en un laberinto de cuadr√≠cula. Su objetivo es encontrar el camino m√°s r√°pido hacia la salida (o el tesoro escondido) sin chocar con los muros ni caer en trampas. Cada celda del laberinto es un estado, y las acciones posibles son moverse en 4 direcciones: arriba, abajo, izquierda o derecha.\n",
    "\n",
    "Estas son las reglas del juego:\n",
    "\n",
    "- **Entorno**: Una cuadr√≠cula 2D (5x5) con una celda de inicio, una meta y varios obst√°culos.\n",
    "- **Estados**: Cada celda de la cuadr√≠cula representa un estado diferente.\n",
    "- **Acciones**: El agente puede moverse en 4 direcciones: arriba, abajo, izquierda o derecha.\n",
    "- **Recompensas**:\n",
    "  - Llegar a la meta: +10 puntos.\n",
    "  - Chocar contra un muro u obst√°culo: -5 puntos.\n",
    "  - Movimiento normal: -1 punto (penalizaci√≥n m√≠nima para evitar movimientos innecesarios).\n",
    "\n",
    "**Visualizaci√≥n del problema:**\n",
    "\n",
    "```plaintext\n",
    "S: Inicio\n",
    "G: Meta\n",
    "X: Obst√°culo\n",
    "\n",
    "    +---+---+---+---+---+\n",
    "    | S |   |   | X |   |\n",
    "    +---+---+---+---+---+\n",
    "    |   |   | X |   |   |\n",
    "    +---+---+---+---+---+\n",
    "    |   | X |   |   | G |\n",
    "    +---+---+---+---+---+\n",
    "    |   |   |   |   |   |\n",
    "    +---+---+---+---+---+\n",
    "    |   |   |   |   |   |\n",
    "    +---+---+---+---+---+\n",
    "\n",
    "```\n",
    "\n",
    "El objetivo del agente en este caso es aprender, a trav√©s de prueba y error, c√≥mo moverse desde la celda de inicio (S) hasta la celda de meta (G) mientras minimiza las penalizaciones.\n",
    "\n",
    "Ahora veamos esto en la pr√°ctica: Configurar esta cuadr√≠cula en Python, inicializar la tabla Q, y comenzar a implementar el algoritmo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Configuraci√≥n del entorno\n",
    "\n",
    "Antes de implementar Q-Learning, necesitamos construir nuestro entorno: la cuadr√≠cula 2D donde el agente aprender√° a navegar. Esto incluye definir los estados, las acciones y las reglas del juego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuraci√≥n inicial\n",
    "\n",
    "Vamos a definir el entorno como una cuadr√≠cula 5x5, donde cada celda representa un estado. Utilizaremos Python para estructurar la cuadr√≠cula y asignar las recompensas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entorno de recompensas:\n",
      "[[-1 -1 -1 -5 -1]\n",
      " [-1 -1 -5 -1 -1]\n",
      " [-1 -5 -1 -1 10]\n",
      " [-1 -1 -1 -1 -1]\n",
      " [-1 -1 -1 -1 -1]]\n"
     ]
    }
   ],
   "source": [
    "# Tama√±o del entorno\n",
    "grid_size = 5\n",
    "\n",
    "# Matriz de recompensas\n",
    "rewards = np.full((grid_size, grid_size), -1)\n",
    "\n",
    "# Definimos la meta y los obst√°culos\n",
    "rewards[2, 4] = 10\n",
    "rewards[0, 3] = -5 \n",
    "rewards[1, 2] = -5\n",
    "rewards[2, 1] = -5\n",
    "\n",
    "# Mostrar el entorno inicial\n",
    "print(\"Entorno de recompensas:\")\n",
    "print(rewards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definir las acciones\n",
    "\n",
    "El agente puede moverse en cuatro direcciones: **arriba, abajo, izquierda, derecha**. Vamos a asignar un √≠ndice a cada acci√≥n para que sea m√°s f√°cil codificar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acciones posibles\n",
    "actions = {\n",
    "    0: \"arriba\",\n",
    "    1: \"abajo\",\n",
    "    2: \"izquierda\",\n",
    "    3: \"derecha\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limitar los movimientos\n",
    "\n",
    "Para evitar que el agente se salga de los l√≠mites de la cuadr√≠cula, definiremos una funci√≥n que valide sus movimientos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_movement(pos, action):\n",
    "    \"\"\"\n",
    "    Valida el movimiento del agente en el entorno.\n",
    "    \"\"\"\n",
    "    x, y = pos\n",
    "    if action == 0 and x > 0:  # Arriba\n",
    "        return (x - 1, y)\n",
    "    elif action == 1 and x < grid_size - 1:  # Abajo\n",
    "        return (x + 1, y)\n",
    "    elif action == 2 and y > 0:  # Izquierda\n",
    "        return (x, y - 1)\n",
    "    elif action == 3 and y < grid_size - 1:  # Derecha\n",
    "        return (x, y + 1)\n",
    "    else:\n",
    "        return pos  # Si el movimiento no es v√°lido, permanece en el mismo lugar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probar el entorno\n",
    "\n",
    "Simulemos un movimiento inicial para verificar que nuestro entorno funciona correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El agente se movi√≥ de (0, 0) a (0, 1)\n",
      "Movimiento inv√°lido: el agente permanece en (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Posici√≥n inicial del agente\n",
    "pos_inicial = (0, 0)\n",
    "\n",
    "# Acci√≥n de prueba: moverse hacia la derecha\n",
    "nueva_pos = validate_movement(pos_inicial, 3)\n",
    "print(f\"El agente se movi√≥ de {pos_inicial} a {nueva_pos}\")\n",
    "\n",
    "# Acci√≥n inv√°lida: intentar moverse hacia arriba desde el borde superior\n",
    "nueva_pos = validate_movement((0, 0), 0)\n",
    "print(f\"Movimiento inv√°lido: el agente permanece en {nueva_pos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Implementaci√≥n del algoritmo Tabular Q-Learning\n",
    "\n",
    "El Q-Learning es un algoritmo basado en tablas donde el agente aprende a tomar decisiones optimizadas usando la funci√≥n Q, que estima la calidad de las acciones en cada estado. Puedes imaginarlo como una hoja de c√°lculo donde el agente anota qu√© tan buena es cada acci√≥n posible en cada celda o posici√≥n del entorno."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1. Inicializaci√≥n de la tabla Q\n",
    "\n",
    "La tabla Q es una matriz donde:\n",
    "\n",
    "- Las filas representan los estados.\n",
    "- Las columnas representan las acciones.\n",
    "- Los valores en la tabla indican qu√© tan buena es una acci√≥n en un estado espec√≠fico.\n",
    "\n",
    "Primero, crearemos una tabla Q llena de ceros y definiremos algunos par√°metros clave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Q inicial:\n",
      "[[[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "# Inicializar la tabla Q\n",
    "q_table = np.zeros((grid_size, grid_size, len(actions)))\n",
    "\n",
    "# Par√°metros del Q-Learning\n",
    "alpha = 0.1  # Tasa de aprendizaje\n",
    "gamma = 0.9  # Factor de descuento\n",
    "epsilon = 1.0  # Probabilidad inicial de exploraci√≥n\n",
    "epsilon_decay = 0.99  # Reducci√≥n de epsilon en cada episodio\n",
    "epsilon_min = 0.1  # Valor m√≠nimo de epsilon\n",
    "\n",
    "# Mostrar la tabla Q inicial\n",
    "print(\"Tabla Q inicial:\")\n",
    "print(q_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Aqu√≠ podemos ver como los valores de la tabla Q valen 0 ahora mismo, esto es porque el agente no tiene experiencia. A medida que aprende, se actualizar√°n estos valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2. Actualizaci√≥n de valores Q\n",
    "\n",
    "Para que nuestro agente mejore sus decisiones con el tiempo, es fundamental que actualice continuamente su tabla Q. Este proceso de aprendizaje se basa en una regla sencilla: cada vez que el agente toma una decisi√≥n, registra la recompensa obtenida. De este modo, construye un historial que le permite identificar las acciones que conducen a los mejores resultados.\n",
    "\n",
    "El agente utiliza una forma matem√°tica para ajustar los valores de su tabla Q. La idea es combinar:\n",
    "\n",
    "1. Lo que ya sabe sobre esa acci√≥n.\n",
    "2. Lo que acaba de aprender tras tomar laa acci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paso a paso del Q-Learning\n",
    "\n",
    "1. **Elegir una acci√≥n**: El agente decide si explorar (acci√≥n aleatoria) o explotar (acci√≥n con el mejor valor Q conocido).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, epsilon):\n",
    "    \"\"\"\n",
    "    Elegir acci√≥n con epsilon-greedy\n",
    "    \"\"\"\n",
    "    if np.random.rand() < epsilon:\n",
    "        return np.random.choice(list(actions.keys()))  # Exploraci√≥n\n",
    "    else:\n",
    "        return np.argmax(q_table[state])  # Explotaci√≥n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta funci√≥n previa, el par√°metro `epsilon` es un valor entre `0` y `1` que determina la probabilidad de que el agente explore, un valor m√°s alto, implica una mayor exploraci√≥n, un valor bajo, implica una mayor explotaci√≥n.\n",
    "\n",
    "2. **Actualizar la tabla Q**: El agente observa la recompensa y el nuevo estado, y actualiza el valor Q de la acci√≥n tomada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_q(state, action, reward, new_state):\n",
    "    \"\"\"\n",
    "    Actualizar la tabla Q usando la f√≥rmula de Q-Learning\n",
    "    \"\"\"\n",
    "    max_q_new = np.max(q_table[new_state])\n",
    "    q_table[state][action] += alpha * (reward + gamma * max_q_new - q_table[state][action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Simulaci√≥n de episodios**: Un episodio representa un intento completo del agente por alcanzar la meta desde el estado inicial. Durante cada episodio, el agente toma decisiones, aprende de sus acciones y actualiza la tabla Q. El proceso se repite hasta que el agente llega a la meta o fracasa al no progresar.\n",
    "\n",
    "**Epsilon decay**:\n",
    "\n",
    "Al final de cada episodio, reducimos el valor de `ùúñ` (epsilon) para que el agente explore menos y aproveche m√°s lo aprendido. Sin embargo, nunca lo dejamos llegar a 0, manteniendo un valor m√≠nimo para que el agente siga explorando nuevas acciones de vez en cuando, asegurando un aprendizaje continuo.\n",
    "\n",
    "A continuaci√≥n, implementamos el bucle principal de entrenamiento del agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 50/500: epsilon=0.61\n",
      "Episode 100/500: epsilon=0.37\n",
      "Episode 150/500: epsilon=0.22\n",
      "Episode 200/500: epsilon=0.13\n",
      "Episode 250/500: epsilon=0.10\n",
      "Episode 300/500: epsilon=0.10\n",
      "Episode 350/500: epsilon=0.10\n",
      "Episode 400/500: epsilon=0.10\n",
      "Episode 450/500: epsilon=0.10\n",
      "Episode 500/500: epsilon=0.10\n"
     ]
    }
   ],
   "source": [
    "# Simulaci√≥n de episodios\n",
    "episodes = 500\n",
    "for episode in range(episodes):\n",
    "    state = (0, 0)  # Inicio\n",
    "    terminated = False\n",
    "\n",
    "    while not terminated:\n",
    "        # Elegir acci√≥n\n",
    "        action = choose_action(state, epsilon)\n",
    "\n",
    "        # Realizar acci√≥n y observar resultado\n",
    "        new_state = validate_movement(state, action)\n",
    "        reward = rewards[new_state]\n",
    "\n",
    "        # Actualizar Q\n",
    "        update_q(state, action, reward, new_state)\n",
    "\n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "\n",
    "        # Verificar si llegamos a la meta\n",
    "        if state == (2, 4):  # Meta\n",
    "            terminated = True\n",
    "\n",
    "    # Reducir epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    # Mostrar progreso\n",
    "    if (episode + 1) % 50 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}: epsilon={epsilon:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durante el entrenamiento, observamos c√≥mo el valor de epsilon se reduce gradualmente:\n",
    "\n",
    "- Durante los primeros 50 episodios, el valor de epsilon es alto (0.61), lo que significa que el agente est√° explorando muchas acciones diferentes para aprender m√°s sobre el entorno.\n",
    "- A medida que progresa, epsilon disminuye gradualmente, hasta estabilizarse en el m√≠nimo de 0.10. En esta etapa, el agente explora poco y prefiere explotar las acciones que sabe que funcionan bien.\n",
    "- Mantener un valor m√≠nimo de epsilon asegura que el agente siga probando acciones nuevas ocasionalmente, lo que evita que quede atrapado en soluciones sub√≥ptimas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Visualizaci√≥n del aprendizaje del agente\n",
    "\n",
    "Una vez ha finalizado el entrenamiento, imprimimos la tabla Q aprendida y simulamos un recorrido para verificar que el agente aprendi√≥ correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabla Q final:\n",
      "[[[-1.8785332  -0.434062   -2.10599579 -3.29662718]\n",
      "  [-3.08869526 -3.0094733  -3.17612643 -1.99810402]\n",
      "  [-2.62952998 -0.16584448 -2.80443954 -3.88639214]\n",
      "  [-2.80794174  3.87345351 -1.74712188 -0.1330756 ]\n",
      "  [-0.44190238  2.52177356 -2.31722053 -0.47489896]]\n",
      "\n",
      " [[-2.28132004  0.62882    -1.02013122 -1.92039245]\n",
      "  [-2.98798573 -3.2364383  -2.93401494  0.01275622]\n",
      "  [-1.63450481  3.84834883 -2.5614837   6.18694006]\n",
      "  [-2.61702793  7.99916355 -1.26140221  4.37311156]\n",
      "  [-0.32899183  8.78423345  0.63695476  0.6075994 ]]\n",
      "\n",
      " [[-1.09747194  1.8098      0.19425919 -0.06589115]\n",
      "  [-2.2707811   0.46342211 -1.29922693  6.18620101]\n",
      "  [ 0.15285859  4.03678038 -0.32019395  8.        ]\n",
      "  [ 5.6856476   5.74689639  5.76655191 10.        ]\n",
      "  [ 0.          0.          0.          0.        ]]\n",
      "\n",
      " [[-0.01752676 -1.18515317  0.78908424  3.122     ]\n",
      "  [-0.09634962  0.88205117  1.03241178  4.58      ]\n",
      "  [ 6.2         2.09480919  1.6551983   5.11488988]\n",
      "  [ 7.96514935 -0.29697138  1.09068891  0.6661142 ]\n",
      "  [ 4.68559     0.          0.37126892  0.        ]]\n",
      "\n",
      " [[-0.97884016 -1.36228881 -1.69269202  0.65754308]\n",
      "  [ 3.00526595 -0.68121851 -1.17095931 -0.5612472 ]\n",
      "  [ 4.26649483  0.08052408 -0.60241864 -0.75215183]\n",
      "  [ 1.74087348 -0.37967622 -0.49444299 -0.19      ]\n",
      "  [ 0.1439     -0.1        -0.1084249  -0.19      ]]]\n",
      "Camino √≥ptimo aprendido por el agente:\n",
      "[(0, 0), (1, 0), (2, 0), (3, 0), (3, 1), (3, 2), (2, 2), (2, 3), (2, 4)]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar tabla Q final\n",
    "print(\"Tabla Q final:\")\n",
    "print(q_table)\n",
    "\n",
    "# Simulaci√≥n de un recorrido √≥ptimo\n",
    "state = (0, 0)\n",
    "path = [state]\n",
    "while state != (2, 4):  # Mientras no lleguemos a la meta\n",
    "    action = np.argmax(q_table[state])\n",
    "    state = validate_movement(state, action)\n",
    "    path.append(state)\n",
    "\n",
    "print(\"Camino √≥ptimo aprendido por el agente:\")\n",
    "print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En base a los resultados, podemos ver el camino √≥ptimo que el agente ha aprendido para llegar a la meta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar el camino\n",
    "visualize_q_learning_path(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro agente sabe c√≥mo navegar la cuadr√≠cula y llegar a la meta mientras evita los obst√°culos. Este ejemplo es simple, pero revela algo poderoso: la capacidad de aprender del entorno y adaptarse con el tiempo.\n",
    "\n",
    "Si nos paramos a pensar, ¬øno es esto similar a nuestras propias vidas? Estamos constantemente explorando caminos, cometiendo errores, encontrando recompensas y aprendiendo. Somos como agentes en nuestro propio entorno, nuestro mundo. siempre buscando nuestro pr√≥ximo movimiento √≥ptimo.\n",
    "\n",
    "Pero, al igual que nuestro agente en la cuadr√≠cula, hay un l√≠mite en lo que podemos hacer con un entorno tan simple. El mundo es vasto, din√°mico y lleno de complejidades. ¬øC√≥mo ser√≠a si pudi√©ramos entrenar a nuestros agentes para enfrentarse a entornos que simulen ese dinamismo? ¬øQu√© secretos podr√≠an desentra√±ar?\n",
    "\n",
    "Con esta pregunta en mente, nos adentramos en **OpenAI Gym**, donde los agentes no solo aprenden, sino que se enfrentan a desaf√≠os m√°s reales y emocionantes. ¬øListo para aplicar lo que hemos aprendido?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. OpenAI Gym y el problema de Cartpole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Introducci√≥n a OpenAI Gym\n",
    "\n",
    "OpenAI Gym es una biblioteca que nos proporciona una colecci√≥n de entornos de simulaci√≥n listos para usar. Desde juegos simples hasta problemas complejos de rob√≥tica, es una herramienta esencial para experimentar con el aprendizaje por refuerzo.\n",
    "\n",
    "Un ejemplo cl√°sico que exploraremos aqu√≠ es CartPole: en este entorno, el agente controla un carrito sobre una pista y su objetivo es mantener un palo en equilibrio el mayor tiempo posible. Si el palo se inclina demasiado o el carrito sale de los l√≠mites de la pista, el episodio termina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Configuraci√≥n del entorno CartPole\n",
    "\n",
    "Primero, configuramos el entorno de OpenAI Gym y exploramos sus propiedades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Espacio de observaci√≥n: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n",
      "Espacio de acciones: Discrete(2)\n",
      "Estado inicial: (array([-0.0370248 , -0.02489001,  0.03096367, -0.03253341], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "# Crear el entorno CartPole\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "\n",
    "# Observar el espacio de estados y acciones\n",
    "print(\"Espacio de observaci√≥n:\", env.observation_space)\n",
    "print(\"Espacio de acciones:\", env.action_space)\n",
    "\n",
    "# Reiniciar el entorno para obtener el estado inicial\n",
    "state = env.reset()\n",
    "print(\"Estado inicial:\", state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠ podemos ver tres elementos importantes:\n",
    "\n",
    "- **Espacio de observaci√≥n**: El espacio de observaci√≥n nos dice qu√© informaci√≥n puede \"ver\" el agente:\n",
    "    - Posici√≥n del carrito.\n",
    "    - Velocidad del carrito.\n",
    "    - √Ångulo del palo.\n",
    "    - Velocidad angular del palo.\n",
    "- **Espacio de acciones**: En CartPole, el agente puede tomar dos acciones:\n",
    "    - Mover el carrito a la izquierda (acci√≥n 0).\n",
    "    - Mover el carrito a la derecha (acci√≥n 1).\n",
    "- **Estado inicial**: Cuando reiniciamos el entorno, obtenemos un estado inicial que describe la posici√≥n y velocidad del carrito y el palo.\n",
    "\n",
    "Estos datos son el \"mundo\" que el agente puede percibir. Para tomar decisiones, necesita interpretar esta informaci√≥n y aprender c√≥mo afecta sus acciones al equilibrio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n del entorno\n",
    "\n",
    "Vamos a visualizar CartPole en acci√≥n para entender mejor c√≥mo se comporta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_and_render(env, policy=None, max_steps=200, gif_name='GIF_CartPole.gif', display_gif=True, use_discretization=True, bins=20):\n",
    "    \"\"\"\n",
    "    Simula un episodio y genera un GIF de la simulaci√≥n.\n",
    "    \n",
    "    Args:\n",
    "        env: Entorno de gymnasium\n",
    "        policy: Funci√≥n que toma un estado y devuelve una acci√≥n. Si es None, usa acciones aleatorias\n",
    "        max_steps: N√∫mero m√°ximo de pasos en la simulaci√≥n\n",
    "        gif_name: Nombre del archivo GIF resultante\n",
    "        display_gif: Si True, muestra el GIF por pantalla\n",
    "    \n",
    "    Returns:\n",
    "        reward_total: Recompensa total del episodio\n",
    "    \"\"\"\n",
    "    in_colab = 'google.colab' in str(get_ipython())\n",
    "    save_path = gif_name if in_colab else f'../docs/imgs/{gif_name}'\n",
    "    if not in_colab:\n",
    "        os.makedirs('../docs/imgs', exist_ok=True)\n",
    "    \n",
    "    state, _ = env.reset()\n",
    "    frames = []\n",
    "    reward_total = 0\n",
    "    \n",
    "    for _ in range(max_steps):\n",
    "        frame = env.render()\n",
    "        frames.append(Image.fromarray(frame))\n",
    "        \n",
    "        if policy is None:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            try:\n",
    "                if use_discretization:\n",
    "                    state_discrete = discretize(state, bins)\n",
    "                    action = np.argmax(policy[state_discrete])\n",
    "                else:\n",
    "                    action = np.argmax(policy[state])\n",
    "            except Exception as e:\n",
    "                action = env.action_space.sample()\n",
    "\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        reward_total += reward\n",
    "        \n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    \n",
    "    env.close()\n",
    "    \n",
    "    if frames:\n",
    "        frames[0].save(\n",
    "            save_path,\n",
    "            save_all=True,\n",
    "            append_images=frames[1:],\n",
    "            duration=50,\n",
    "            loop=0\n",
    "        )\n",
    "    \n",
    "    if display_gif and frames:\n",
    "        display.clear_output(wait=True)\n",
    "        return display.Image(save_path), reward_total\n",
    "    \n",
    "    return reward_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompensa con pol√≠tica aleatoria: 44.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "display_gif = False\n",
    "if display_gif:\n",
    "    gif, reward = simulate_and_render(env, policy=None, gif_name='GIF_CartPole_Random.gif', display_gif=True)\n",
    "    display.display(gif)\n",
    "else:\n",
    "    reward = simulate_and_render(env, policy=None, gif_name='GIF_CartPole_Random.gif', display_gif=False)\n",
    "print(f\"Recompensa con pol√≠tica aleatoria: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GIF_CartPole](../docs/imgs/GIF_CartPole.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como puedes observar, el carrito intenta mantener el palo en equilibrio el mayor tiempo posible, movi√©ndose de un lado a otro para evitar que se caiga o que salga de los l√≠mites de la pista. Sin embargo, cuando el palo supera un cierto √°ngulo de inclinaci√≥n o el carrito se desplaza demasiado lejos, el episodio termina y el entorno se reinicia autom√°ticamente.\n",
    "\n",
    "En particular, el entorno se reinicia cuando:\n",
    "- El palo se inclina m√°s de 12 grados.\n",
    "- El carrito se desplaza m√°s de 2.4 unidades de distancia del centro.\n",
    "\n",
    "Estos criterios est√°n predefinidos en OpenAI Gym para simplificar el problema y permitir que el agente pueda enfocarse en estrategias claras para maximizar su recompensa dentro de un marco limitado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Implementaci√≥n de Q-Learning para CartPole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para CartPole, necesitamos ajustar el enfoque de Q-Learning. Esto se debe a que:\n",
    "\n",
    "1. A diferencia de nuestra cuadr√≠cula anterior, CartPole tiene un espacio continuo para las observaciones (valores como posici√≥n o √°ngulo). Esto significa que el agente podr√≠a enfrentarse a infinitos estados posibles.\n",
    "2. Cada acci√≥n afecta no solo al presente, sino tambi√©n a las posibilidades futuras. Si mueves el carrito en la direcci√≥n equivocada, el palo podr√≠a caer m√°s r√°pido.\n",
    "\n",
    "Para manejar esto, nuestro primer paso ser√° discretizar el espacio de observaci√≥n.\n",
    "\n",
    "### ¬øQu√© es discretizar?\n",
    "\n",
    "**Discretizar** significa dividir el espacio continuo en categor√≠as o bins manejables, en otras palabras, reducir el n√∫mero de estados posibles.\n",
    "\n",
    "Por ejemplo, supongamos que tenemos un term√≥metro que mide temperaturas entre 0.00¬∞C y 100.00¬∞C. Este es un espacio continuo porque el term√≥metro puede mostrar cualquier valor decimal, como 22.37¬∞C o 89.56¬∞C. Sin embargo, si lo dividimos en 10 rangos (bins), podr√≠amos agrupar las temperaturas as√≠:\n",
    "\n",
    "Bin 0: 0-10¬∞C\n",
    "Bin 1: 10-20¬∞C\n",
    "Bin 2: 20-30¬∞C\n",
    "...\n",
    "Bin 9: 90-100¬∞C\n",
    "\n",
    "De esta forma, si la temperatura es 22.37¬∞C, cae en el Bin 2 (20-30¬∞C). Esto simplifica las decisiones, ya que en lugar de considerar infinitos valores, s√≥lo tenemos que trabajar con 10 categor√≠as discretas.\n",
    "\n",
    "B√°sicamente, buscamos conseguir:\n",
    "1. Simplificar el problema acotando el n√∫mero de estados posibles para poder dibujarlos en una tabla Q.\n",
    "2. Reducir la complejidad computacional (cantidad de informaci√≥n a procesar por parte del agente)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado continuo: [ 0.00015232 -0.04569796 -0.00737907 -0.00991326]\n",
      "Estado discreto: (np.int64(9), np.int64(9), np.int64(9), np.int64(9))\n"
     ]
    }
   ],
   "source": [
    "# Definir los l√≠mites del espacio de observaci√≥n\n",
    "min_space = env.observation_space.low\n",
    "max_space = env.observation_space.high\n",
    "\n",
    "# Limitar valores extremos para estabilidad\n",
    "min_space[1] = -3.4  # Velocidad del carrito\n",
    "max_space[1] = 3.4\n",
    "min_space[3] = -3.4  # Velocidad angular del palo\n",
    "max_space[3] = 3.4\n",
    "\n",
    "# Dividir cada dimensi√≥n en bins\n",
    "bins = 20\n",
    "\n",
    "# Funci√≥n para discretizar un estado continuo\n",
    "def discretize(state, bins):\n",
    "    \"\"\"Convierte un estado continuo en uno discreto usando bins.\"\"\"\n",
    "    # Usamos ranges en lugar de range para evitar conflicto con la funci√≥n built-in\n",
    "    ranges = [np.linspace(min_space[i], max_space[i], bins) for i in range(len(state))]\n",
    "    return tuple(np.digitize(state[i], ranges[i]) - 1 for i in range(len(state)))\n",
    "\n",
    "# Probar la discretizaci√≥n\n",
    "state_continuous = env.reset()[0]\n",
    "state_discrete = discretize(state_continuous, bins)\n",
    "print(\"Estado continuo:\", state_continuous)\n",
    "print(\"Estado discreto:\", state_discrete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, cada estado continuo se ha convertido en un estado discreto con 20 categor√≠as para cada variable. Esto simplifica enormemente el algoritmo, pero no sacrifica la capacidad de aprendizaje del agente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializaci√≥n de la tabla Q\n",
    "\n",
    "La tabla Q es donde almacenaremos lo aprendido. Representa las estimaciones del agente sobre la calidad de cada acci√≥n en cada estado discreto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones de la tabla Q: (20, 20, 20, 20, 2)\n"
     ]
    }
   ],
   "source": [
    "# Dimensiones de la tabla Q\n",
    "dimensions = (bins,) * len(min_space) + (env.action_space.n,)\n",
    "\n",
    "# Crear la tabla Q llena de ceros\n",
    "q_table = np.zeros(dimensions)\n",
    "print(\"Dimensiones de la tabla Q:\", q_table.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este output podemos ver c√≥mo est√° organizada la tabla Q. Cada n√∫mero representa una dimensi√≥n del espacio de estados y acciones:\n",
    "\n",
    "- **(20, 20, 20, 20)**: Estas cuatro primeras dimensiones corresponden a las caracter√≠sticas del entorno discretizadas en 20 categor√≠as (bins) cada una:\n",
    "    - Posici√≥n del carrito.\n",
    "    - Velocidad del carrito.\n",
    "    - √Ångulo del palo.\n",
    "    - Velocidad angular del palo.\n",
    "\n",
    "Juntas, forman todas las posibles combinaciones de estados discretos del entorno. En este caso hay $20^4 = 160.000$ estados posibles.\n",
    "\n",
    "- **(2)**: La √∫ltima dimensi√≥n representa las dos acciones posibles:\n",
    "    - Mover el carrito a la izquierda.\n",
    "    - Mover el carrito a la derecha.\n",
    "\n",
    "Estas dos acciones son las que el agente puede tomar para interactuar con el entorno.\n",
    "\n",
    "En definitiva, nuestra tabla Q almacena dos valores (uno para cada acci√≥n) para cada una de las $160.000$ combinaciones de estados posibles.\n",
    "\n",
    "> **Nota**: Aunque esta tabla es manejable para este problema, en entornos m√°s complejos, necesitar√≠amos m√©todos m√°s avanzados como redes neuronales para estimar los valores Q."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Entrenamiento del agente\n",
    "\n",
    "Finalmente, entrenaremos al agente para que aprenda a maximizar la duraci√≥n del equilibrio del palo. Utilizaremos exploraci√≥n (epsilon-greedy) al principio y, poco a poco, dejaremos que el agente conf√≠e m√°s en lo aprendido (explotaci√≥n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 500/5000, average reward: 30.064\n",
      "Episode 1000/5000, average reward: 59.844\n",
      "Episode 1500/5000, average reward: 81.1\n",
      "Episode 2000/5000, average reward: 98.578\n",
      "Episode 2500/5000, average reward: 116.322\n",
      "Episode 3000/5000, average reward: 114.32\n",
      "Episode 3500/5000, average reward: 123.232\n",
      "Episode 4000/5000, average reward: 126.588\n",
      "Episode 4500/5000, average reward: 125.578\n",
      "Episode 5000/5000, average reward: 143.768\n"
     ]
    }
   ],
   "source": [
    "# Par√°metros de entrenamiento\n",
    "alpha = 0.5  # Tasa de aprendizaje\n",
    "gamma = 0.95  # Factor de descuento\n",
    "epsilon = 1.0  # Probabilidad de exploraci√≥n\n",
    "epsilon_decay = 0.999  # Decadencia de epsilon\n",
    "epsilon_min = 0.2  # Valor m√≠nimo de epsilon\n",
    "\n",
    "# Entrenamiento\n",
    "episodes = 5000\n",
    "rewards = []\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state_continuous = env.reset()[0]\n",
    "    state = discretize(state_continuous, bins)\n",
    "    reward_total = 0\n",
    "    terminated = False\n",
    "\n",
    "    while not terminated:\n",
    "        # Elegir acci√≥n con epsilon-greedy\n",
    "        if np.random.rand() < epsilon:\n",
    "            action = np.random.choice(env.action_space.n)  # Exploraci√≥n\n",
    "        else:\n",
    "            action = np.argmax(q_table[state])  # Explotaci√≥n\n",
    "\n",
    "        # Tomar acci√≥n y observar resultado\n",
    "        new_state_continuous, reward, terminated, truncated, info = env.step(action)\n",
    "        new_state = discretize(new_state_continuous, bins)\n",
    "\n",
    "        # Actualizar la tabla Q\n",
    "        max_q = np.max(q_table[new_state])\n",
    "        q_table[state][action] += alpha * (reward + gamma * max_q - q_table[state][action])\n",
    "\n",
    "        # Cambiar al nuevo estado\n",
    "        state = new_state\n",
    "        reward_total += reward\n",
    "\n",
    "    # Reducir epsilon\n",
    "    epsilon = max(epsilon_min, epsilon * epsilon_decay)\n",
    "\n",
    "    # Guardar recompensa del episodio\n",
    "    rewards.append(reward_total)\n",
    "\n",
    "    if (episode + 1) % 500 == 0:\n",
    "        print(f\"Episode {episode + 1}/{episodes}, average reward: {np.mean(rewards[-500:])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. An√°lisis de resultados y reflexiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An√°lisis de los resultados\n",
    "\n",
    "- **Mejora Continua**: Como vemos, la recompensa cada vez aumenta m√°s, lo que indica que el agente est√° aprendiendo. Hacia los episodios intermedios (alrededor de 2.000), la recompensa supera los 100, lo que significa que el agente ha aprendido estrategias que mantienen el palo equilibrado m√°s tiempo.\n",
    "- **Convergencia**: El aumento de la recompensa hacia los √∫ltimos episodios hasta alcanzar 147 aproximadamente en el episodio final, sugiere que el agente converge hacia una pol√≠tica efectiva y est√° maximizando su recompensa en la mayor√≠a de las ocasiones.\n",
    "\n",
    "En definitiva, el agente ha aprendido con √©xito: Las recompensas son crecientes y su estabilizaci√≥n sugieren que el agente ha adquirido una pol√≠tica efectiva para equilibrar el palo.\n",
    "\n",
    "Sin embargo, aunque vemos que el agente est√° aprendiendo, la recompensa m√°xima en CartPole es 500, es decir, que todav√≠a queda bastante margen para mejorar.\n",
    "\n",
    "### Posibles pasos para mejorar el rendimiento\n",
    "\n",
    "\n",
    "- **Aumentar los episodios de entrenamiento**: Entrenar por m√°s tiempo podr√≠a permitir que el agente refine a√∫n m√°s su pol√≠tica y alcance recompensas m√°s altas. Adem√°s, por ahora hemos visto que la recompensa acumulada del agente sigue subiendo, lo que sugiere que todav√≠a no ha convergido.\n",
    "- **Explorar `epsilon_decay` din√°mico**: En lugar de disminuir `epsilon` linealmente, podr√≠amos usar un enfoque din√°mico que reduzca m√°s r√°pido al principio y m√°s lento hacia el final para equilibrar exploraci√≥n y explotaci√≥n.\n",
    "- **Probar estrategias avanzadas**: Otra posibilidad ser√≠a introducir m√©todos m√°s sofisticados como **Double Q-Learning** o **Deep Q-Learning (DQN)** que pueden llevar al agente a dominar completamente el problema.\n",
    "- **Visualizar el comportamiento del agente**: Simular episodios despu√©s del entrenamiento para observar c√≥mo el agente toma decisiones. Esto puede revelar si hay √°reas espec√≠ficas donde su pol√≠tica a√∫n necesita mejoras.\n",
    "\n",
    "### Visualizaci√≥n de la evoluci√≥n del agente\n",
    "\n",
    "Ahora vamos a visualizar el progreso y comportamiento del agente.\n",
    "\n",
    "Primero vamos a graficar las recompensas acumuladas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(rewards)\n",
    "plt.xlabel(\"Episodios\")\n",
    "plt.ylabel(\"Recompensa acumulada\")\n",
    "plt.title(\"Progreso del agente en CartPole\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recompensa total del episodio: 200.0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "display_gif = False\n",
    "if display_gif:\n",
    "    gif, reward = simulate_and_render(env, policy=q_table, gif_name='GIF_CartPole_Q-Learning.gif', display_gif=True)\n",
    "    display.display(gif)\n",
    "else:\n",
    "    reward = simulate_and_render(env, policy=q_table, gif_name='GIF_CartPole_Q-Learning.gif', display_gif=False)\n",
    "print(f\"Recompensa total del episodio: {reward}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![GIF_CartPole_Q-Learning](../docs/imgs/GIF_CartPole_Q-Learning.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Conclusi√≥n\n",
    "\n",
    "Nos vamos a quedar por aqu√≠ con este ejercicio, pero te animo a que explores alguna de las propuestas que hemos comentado para intentar mejorar el rendimiento del agente.\n",
    "\n",
    "En este experimento, hemos llevado a nuestro agente desde la completa ignorancia hasta la capacidad de equilibrar un palo en el entorno din√°mico de CartPole. No solo aprendi√≥, sino que mejor√≥ gradualmente hasta lograr recompensas promedio s√≥lidas. Pero lo que hace esto realmente fascinante no es solo el n√∫mero de recompensas, sino lo que nos dice sobre el aprendizaje por refuerzo y, en cierto sentido, sobre nosotros mismos.\n",
    "\n",
    "## ¬øQu√© aprendimos?\n",
    "\n",
    "1. **El poder de la retroalimentaci√≥n**: Al igual que nosotros, el agente aprendi√≥ con cada intento, cada error y cada peque√±o √©xito. Esa simple regla de \"intenta, falla, ajusta y repite\" es fundamental tanto para los agentes de RL como para la vida misma.\n",
    "2. **Exploraci√≥n para crecer, explotaci√≥n para avanzar**: Al principio, el agente necesitaba explorar. Probar acciones, incluso si no parec√≠an √≥ptimas, le permiti√≥ descubrir estrategias que nunca hubiera encontrado de otro modo. M√°s tarde, comenz√≥ a explotar lo que sab√≠a para maximizar su recompensa. ¬øNo es eso lo que hacemos en nuestras propias vidas? Exploramos nuevos caminos, aprendemos y luego utilizamos ese conocimiento para avanzar.\n",
    "3. **La importancia de un entorno estructurado**: Crear un entorno controlado y estructurado como CartPole permiti√≥ al agente aprender sin riesgos externos. Esto no es muy diferente de c√≥mo nos preparamos para enfrentar desaf√≠os reales: practicamos, simulamos, y luego aplicamos lo aprendido en el mundo real.\n",
    "\n",
    "## ¬øPr√≥ximos pasos?\n",
    "\n",
    "CartPole fue un desaf√≠o controlado. Un primer paso. Pero el mundo es mucho m√°s complejo. Imagina entrenar agentes que optimicen sistemas de energ√≠a, manejen veh√≠culos aut√≥nomos o dise√±en estrategias para enfrentar problemas globales como el cambio clim√°tico.\n",
    "\n",
    "El aprendizaje por refuerzo no es solo una herramienta; es un modelo de c√≥mo podemos enfrentarnos a nuestros propios desaf√≠os, uno peque√±o y manejable a la vez.\n",
    "\n",
    "Al final, lo que hace que el aprendizaje por refuerzo sea tan poderoso no es solo su capacidad para resolver problemas en un entorno simulado. Es c√≥mo nos recuerda algo profundamente humano: el aprendizaje ocurre en ciclos. Exploramos, explotamos, fallamos y ajustamos. En este proceso, no solo nos hacemos mejores, sino que tambi√©n construimos el conocimiento necesario para enfrentar desaf√≠os m√°s grandes.\n",
    "\n",
    "¬øQu√© pasar√° si llevamos esta mentalidad a nuestros propios proyectos y desaf√≠os? S√≥lo queda explorar mientras explotamos lo que ya sabemos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toma de acci√≥n para el aprendizaje: El RL en tu vida\n",
    "\n",
    "El aprendizaje por refuerzo no s√≥lo nos permite entrenar agentes; tambi√©n nos ense√±a lecciones valiosas sobre c√≥mo enfrentar desaf√≠os, tomar decisiones estrat√©gicas y aprender de nuestras experiencias. Aqu√≠ tienes algunas acciones y reflexiones para llevar lo aprendido en este notebook a tu d√≠a a d√≠a, tanto en lo personal como en lo profesional.\n",
    "\n",
    "1. **Encuentra tus recompensas**: En el aprendizaje por refuerzo, todo se basa en maximizar recompensas acumuladas. ¬øCu√°l es tu recompensa en este momento? ¬øQu√© quieres maximizar? Puede ser mejorar tus habilidades, lograr un objetivo personal o resolver un problema en tu trabajo. P√°rate a definir tus recompensas con claridad. ¬øQu√© peque√±os pasos puedes tomar hoy para acercarte a ellas?\n",
    "2. **Aprende de tus acciones**: As√≠ como el agente ajusta su pol√≠tica despu√©s de cada acci√≥n, t√∫ puedes reflexionar sobre tus decisiones pasadas. Preg√∫ntate:\n",
    "    - ¬øQu√© decisiones recientes me acercaron a mis objetivos?\n",
    "    - ¬øQu√© decisiones puedo ajustar para evitar errores en el futuro?\n",
    "3. **Explora m√°s antes de explotar**: Es f√°cil quedarse en lo que ya conoces, pero recuerda la importancia de la exploraci√≥n para maximizar recompensas. Busca nuevos desaf√≠os, haz algo que no hayas hecho antes y prueba caminos que no hayas considerado.\n",
    "   - *Algunos ejemplos*: Aprende una nueva habilidad, prueba una herramienta diferente en tu trabajo, ve a la √≥pera o a ver una pel√≠cula que no ver√≠as de otra forma, o experimenta con una estrategia no convencional.\n",
    "4. **Define tu entorno**: Los entornos bien dise√±ados, como OpenAI Gym, permiten que los agentes aprendan de forma segura. ¬øC√≥mo puedes dise√±ar un entorno que te ayude a aprender mejor?\n",
    "   - *Algunos ejemplos*: Crea rutinas, elimina distracciones y establece metas claras para que tu entorno te impulse hacia el √©xito.\n",
    "5. **Balancea el corto y el largo plazo**: El agente considera tanto las recompensas inmediatas como las futuras, recuerda que hay cosas que se acumulan y crecen exponencialmente. Aplica esto tambi√©n en tu vida:\n",
    "   - ¬øQu√© decisiones hoy tienen beneficios inmediatos?\n",
    "   - ¬øQu√© inversiones a largo plazo pueden ser m√°s gratificantes?\n",
    "6. **Redefine tus fracasos**: Cada episodio donde el agente fall√≥ en equilibrar el palo fue una oportunidad para aprender. De la misma forma, cada \"fracaso\" en tu vida es una experiencia valiosa. Es buena idea preguntarse siempre:\n",
    "   - ¬øQu√© aprend√≠ de esta situaci√≥n?\n",
    "   - ¬øC√≥mo puedo ajustar mi estrategia para obtener mejores resultados cuando me encuentro en una situaci√≥n similar?\n",
    "7. **Automatiza tus decisiones estrat√©gicas**: En RL, las pol√≠ticas ayudan al agente a tomar decisiones r√°pidas y efectivas. Crea tus propias \"pol√≠ticas\" personales.\n",
    "   - *Ejemplo*: Si detectas un problema recurrente, dise√±a una estrategia clara para enfrentarlo en el futuro sin perder tiempo. En mi caso, tengo un vault de obsidian con una carpeta de \"estrategias\" donde guardo todas las estrategias que uso para resolver problemas recurrentes. Tambi√©n tengo piezas de proyectos pasados que puedo reutilizar en proyectos futuros (Siempre dejando espacio a la exploraci√≥n y los ajustes).\n",
    "8. **Visualiza tu progreso**: As√≠ como graficamos las recompensas del agente, detente y observa c√≥mo has progresado. Mide tus logros y reflexiona sobre cu√°nto has crecido en los √∫ltimos tiempos.\n",
    "\n",
    "\n",
    "## Reflexi√≥n Final\n",
    "\n",
    "El aprendizaje por refuerzo nos ense√±a a tomar decisiones estrat√©gicas y aprender continuamente. Nos invita a reflexionar sobre nuestras recompensas, explorar lo desconocido y ajustar nuestras estrategias para enfrentar un mundo din√°mico.\n",
    "\n",
    "Cada acci√≥n que tomas es una oportunidad para aprender. Cada recompensa es un paso hacia algo m√°s grande. Y cada \"fracaso\" es solo un episodio m√°s en tu curva de aprendizaje.\n",
    "\n",
    "La vida est√° llena de desaf√≠os, de palos que hay que equilibrar. No siempre lo haremos de la mejor forma. A veces se nos caer√° el palo. Pero el verdadero truco est√° en seguir intent√°ndolo, ajustando nuestras decisiones y aprovechando todo lo que aprendemos en el camino."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias y Recursos\n",
    "\n",
    "**Recursos internos**\n",
    "\n",
    "- [Manual de uso de estos notebooks](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/docs/manual-notebooks.md) \n",
    "- [Notebook 00: Empieza aqu√≠](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/00_Empieza-aqu√≠.ipynb)\n",
    "- [Notebook 01: Aprendizaje Supervisado](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/01_Aprendizaje-Supervisado.ipynb)\n",
    "- [Notebook 02: Aprendizaje No Supervisado](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/02_Aprendizaje-No-Supervisado.ipynb)\n",
    "\n",
    "**Documentaci√≥n**\n",
    "\n",
    "- [OpenAI Gym](https://gymnasium.farama.org/)\n",
    "\n",
    "**Otros recursos**\n",
    "\n",
    "- [Playground de RL](https://alazareva.github.io/rl_playground/#agentType=expectedSarsa&learningRate=0.5&epsilon=0.05&discount=0.9&showVisits=true&showQ=true) - Aqu√≠ puedes jugar con los par√°metros de los algoritmos de RL en un entorno interactivo.\n",
    "- [Spinning Up](https://spinningup.openai.com/en/latest/index.html) - Una gu√≠a pr√°ctica para aprender RL, con implementaciones en PyTorch y TensorFlow. Por si quieres profundizar m√°s a fondo en el tema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TallerML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
