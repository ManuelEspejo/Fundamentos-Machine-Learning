{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/03_Aprendizaje-Por-Refuerzo.ipynb) üëàüèª‚Äã **Pulsar para abrir en Colab‚Äã**\n",
    "\n",
    "# ¬øC√≥mo usar estos notebooks?\n",
    "\n",
    "Si este es el primer notebook que abres en este repositorio, te recomiendo que antes leas el [Manual de uso de estos notebooks](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/docs/manual-notebooks.md) que he creado para que te familiarices con el proyecto y las distintas rutas que puedes seguir, luego puedes volver aqu√≠ y continuar.\n",
    "\n",
    "En este notebook, vamos a profundizar en la **interpretabilidad de los modelos de IA**.\n",
    "\n",
    "Por otra parte, si a√∫n no has revisado el notebook \"[00_Empieza-aqu√≠.ipynb](https://github.com/ManuelEspejo/Machine-Learning-Bases/blob/main/notebooks/00_Empieza-aqu√≠.ipynb)\", te sugiero que le eches un vistazo primero para conocer los conceptos b√°sicos. Pero si ya tienes una idea clara de los conceptos b√°sicos y quieres pasar a la pr√°ctica, ¬°est√°s en el lugar correcto!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Interpretabilidad de los Modelos\n",
    "\n",
    "Cuando entrenamos modelos de Machine Learning, uno de los mayores desaf√≠os no es solo que el modelo funcione bien, sino entender **c√≥mo** y **por qu√©** toma sus decisiones. Este es el coraz√≥n de la interpretabilidad: poder responder a preguntas como *\"¬øpor qu√© este modelo rechaz√≥ mi pr√©stamo?\"* o *\"¬øpor qu√© dice que este tumor es maligno?\"*.\n",
    "\n",
    "## ¬øPor qu√© es importante?\n",
    "\n",
    "La interpretabilidad de los modelos no es solo un tema t√©cnico, es una cuesti√≥n de confianza, responsabilidad y toma de decisiones √©ticas. Aqu√≠ te dejo tres razones principales por las que es crucial:\n",
    "\n",
    "1. **Confianza en el modelo:** Si no entiendes c√≥mo funciona un modelo, ¬øc√≥mo puedes confiar en √©l? Esto es especialmente importante en √°reas cr√≠ticas como la salud, las finanzas y la justicia, donde las decisiones tienen un impacto directo en la vida de las personas.\n",
    "\n",
    "2. **Cumplimiento de normativas:** Cada vez m√°s regulaciones exigen que los modelos de IA sean explicables, como el [GDPR en Europa](https://gdpr-info.eu/), que establece el \"derecho a explicaci√≥n\" para decisiones automatizadas.\n",
    "\n",
    "> **Recursos:** Si quieres saber m√°s sobre el GDPR, te recomiendo explorar este [GPT personalizado](https://chatgpt.com/g/g-JvCAAqPCj-gdpr-expert), est√° muy bien construido.\n",
    "\n",
    "3. **Impacto social y √©tico:** Un modelo opaco puede amplificar sesgos y tomar decisiones injustas. Por ejemplo, si un modelo de contrataci√≥n favorece a un grupo sobre otro sin una justificaci√≥n clara, estar√≠amos perpetuando desigualdades.\n",
    "\n",
    "En resumen, la interpretabilidad no es solo un *\"nice to have\"*, es una necesidad fundamental en cualquier aplicaci√≥n de IA que impacte el mundo real.\n",
    "\n",
    "\n",
    "## ¬øQu√© vamos a ver?\n",
    "\n",
    "En este notebook, nos sumergiremos en el fascinante mundo de la interpretabilidad y exploraremos c√≥mo podemos explicar y justificar las decisiones de dos tipos de modelos muy diferentes: un **√°rbol de decisi√≥n** y una **red neuronal**.\n",
    "\n",
    "Al final de este notebook, habr√°s aprendido:\n",
    "\n",
    "- **Qu√© es la interpretabilidad y por qu√© importa**, con ejemplos del mundo real.  \n",
    "- **C√≥mo entrenar y visualizar un √°rbol de decisi√≥n,** uno de los modelos m√°s intuitivos.  \n",
    "- **C√≥mo trabajar con redes neuronales y explorar su interpretabilidad,** utilizando herramientas como SHAP.  \n",
    "- **La comparaci√≥n entre ambos enfoques,** destacando los pros y los contras de cada uno.\n",
    "\n",
    "La meta no es solo entender qu√© modelo funciona mejor, sino tambi√©n aprender a tomar decisiones informadas sobre cu√°ndo priorizar la interpretabilidad frente a la precisi√≥n.\n",
    "\n",
    "**¬øListo para desentra√±ar las decisiones de tus modelos y convertirte en un maestro de la interpretabilidad?**\n",
    "\n",
    "**¬°Vamos all√°! üöÄ**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
